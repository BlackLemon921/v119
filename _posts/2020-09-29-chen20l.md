---
title: Differentiable Product Quantization for End-to-End Embedding Compression
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/chen20l/chen20l.pdf
url: http://proceedings.mlr.press/v119/chen20l.html
abstract: Embedding layers are commonly used to map discrete symbols into continuous
  embedding vectors that reflect their semantic meanings. Despite their effectiveness,
  the number of parameters in an embedding layer increases linearly with the number
  of symbols and poses a critical challenge on memory and storage constraints. In
  this work, we propose a generic and end-to-end learnable compression framework termed
  differentiable product quantization (DPQ). We present two instantiations of DPQ
  that leverage different approximation techniques to enable differentiability in
  end-to-end learning. Our method can readily serve as a drop-in alternative for any
  existing embedding layer. Empirically, DPQ offers significant compression ratios
  (14-238X) at negligible or no performance cost on 10 datasets across three different
  language tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen20l
month: 0
tex_title: Differentiable Product Quantization for End-to-End Embedding Compression
firstpage: 1617
lastpage: 1626
page: 1617-1626
order: 1617
cycles: false
bibtex_author: Chen, Ting and Li, Lala and Sun, Yizhou
author:
- given: Ting
  family: Chen
- given: Lala
  family: Li
- given: Yizhou
  family: Sun
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
software: https://github.com/chentingpc/dpq_embedding_compression
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/chen20l/chen20l-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
