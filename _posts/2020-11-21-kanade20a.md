---
title: Learning and Evaluating Contextual Embedding of Source Code
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/kanade20a/kanade20a.pdf
url: http://proceedings.mlr.press/v119/kanade20a.html
abstract: Recent research has achieved impressive results on understanding and improving
  source code by building up on machine-learning techniques developed for natural
  languages. A significant advancement in natural-language understanding has come
  with the development of pre-trained contextual embeddings, such as BERT, which can
  be fine-tuned for downstream tasks with less labeled data and training budget, while
  achieving better accuracies. However, there is no attempt yet to obtain a high-quality
  contextual embedding of source code, and to evaluate it on multiple program-understanding
  tasks simultaneously; that is the gap that this paper aims to mitigate. Specifically,
  first, we curate a massive, deduplicated corpus of 7.4M Python files from GitHub,
  which we use to pre-train CuBERT, an open-sourced code-understanding BERT model;
  and, second, we create an open-sourced benchmark that comprises five classification
  tasks and one program-repair task, akin to code-understanding tasks proposed in
  the literature before. We fine-tune CuBERT on our benchmark tasks, and compare the
  resulting models to different variants of Word2Vec token embeddings, BiLSTM and
  Transformer models, as well as published state-of-the-art models, showing that CuBERT
  outperforms them all, even with shorter training, and with fewer labeled examples.
  Future work on source-code embedding can benefit from reusing our benchmark, and
  from comparing against CuBERT models as a strong baseline.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kanade20a
month: 0
tex_title: Learning and Evaluating Contextual Embedding of Source Code
firstpage: 5110
lastpage: 5121
page: 5110-5121
order: 5110
cycles: false
bibtex_author: Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi,
  Kensen
author:
- given: Aditya
  family: Kanade
- given: Petros
  family: Maniatis
- given: Gogul
  family: Balakrishnan
- given: Kensen
  family: Shi
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/kanade20a/kanade20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
