---
title: 'Fiedler Regularization: Learning Neural Networks with Graph Sparsity'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/tam20a/tam20a.pdf
url: http://proceedings.mlr.press/v119/tam20a.html
abstract: We introduce a novel regularization approach for deep learning that incorporates
  and respects the underlying graphical structure of the neural network. Existing
  regularization methods often focus on penalizing weights in a global/uniform manner
  that ignores the connectivity structure of the neural network. We propose to use
  the Fiedler value of the neural networkâ€™s underlying graph as a tool for regularization.
  We provide theoretical support for this approach via spectral graph theory. We show
  several useful properties of the Fiedler value that make it suitable for regularization.
  We provide an approximate, variational approach for faster computation during training.
  We provide an alternative formulation of this framework in the form of a structurally
  weighted L1 penalty, thus linking our approach to sparsity induction. We performed
  experiments on datasets that compare Fiedler regularization with traditional regularization
  methods such as Dropout and weight decay. Results demonstrate the efficacy of Fiedler
  regularization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tam20a
month: 0
tex_title: 'Fiedler Regularization: Learning Neural Networks with Graph Sparsity'
firstpage: 9346
lastpage: 9355
page: 9346-9355
order: 9346
cycles: false
bibtex_author: Tam, Edric and Dunson, David
author:
- given: Edric
  family: Tam
- given: David
  family: Dunson
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
