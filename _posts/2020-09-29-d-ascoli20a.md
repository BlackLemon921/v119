---
title: 'Double Trouble in Double Descent: Bias and Variance(s) in the Lazy Regime'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/d-ascoli20a/d-ascoli20a.pdf
url: http://proceedings.mlr.press/v119/d'ascoli20a.html
abstract: 'Deep neural networks can achieve remarkable generalization performances
  while interpolating the training data. Rather than the U-curve emblematic of the
  bias-variance trade-off, their test error often follows a "double descent"—a mark
  of the beneficial role of overparametrization. In this work, we develop a quantitative
  theory for this phenomenon in the so-called lazy learning regime of neural networks,
  by considering the problem of learning a high-dimensional function with random features
  regression. We obtain a precise asymptotic expression for the bias-variance decomposition
  of the test error, and show that the bias displays a phase transition at the interpolation
  threshold, beyond it which it remains constant. We disentangle the variances stemming
  from the sampling of the dataset, from the additive noise corrupting the labels,
  and from the initialization of the weights. We demonstrate that the latter two contributions
  are the crux of the double descent: they lead to the overfitting peak at the interpolation
  threshold and to the decay of the test error upon overparametrization. We quantify
  how they are suppressed by ensembling the outputs of $K$ independently initialized
  estimators. For $K\rightarrow \infty$, the test error is monotonously decreasing
  and remains constant beyond the interpolation threshold. We further compare the
  effects of overparametrizing, ensembling and regularizing. Finally, we present numerical
  experiments on classic deep learning setups to show that our results hold qualitatively
  in realistic lazy learning scenarios.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: d-ascoli20a
month: 0
tex_title: 'Double Trouble in Double Descent: Bias and Variance(s) in the Lazy Regime'
firstpage: 2280
lastpage: 2290
page: 2280-2290
order: 2280
cycles: false
bibtex_author: D'Ascoli, St{\'e}phane and Refinetti, Maria and Biroli, Giulio and
  Krzakala, Florent
author:
- given: Stéphane
  family: D’Ascoli
- given: Maria
  family: Refinetti
- given: Giulio
  family: Biroli
- given: Florent
  family: Krzakala
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/d-ascoli20a/d-ascoli20a-supp.pdf
- label: Other Files
  link: https://media.icml.cc/Conferences/ICML2020/v119/d'ascoli20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
