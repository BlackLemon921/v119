---
title: Quantum Expectation-Maximization for Gaussian mixture models
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/kerenidis20a/kerenidis20a.pdf
url: http://proceedings.mlr.press/v119/kerenidis20a.html
abstract: We define a quantum version of Expectation-Maximization (QEM), a fundamental
  tool in unsupervised machine learning, often used to solve Maximum Likelihood (ML)
  and Maximum A Posteriori (MAP) estimation problems. We use QEM to fit a Gaussian
  Mixture Model, and show how to generalize it to fit mixture models with base distributions
  in the exponential family. Given quantum access to a dataset, our algorithm has
  convergence and precision guarantees similar to the classical algorithm, while the
  runtime is polylogarithmic in the number of elements in the training set and polynomial
  in other parameters, such as the dimension of the feature space and the number of
  components in the mixture. We discuss the performance of the algorithm on a dataset
  that is expected to be classified successfully by classical EM and provide guarantees
  for its runtime.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kerenidis20a
month: 0
tex_title: Quantum Expectation-Maximization for {G}aussian mixture models
firstpage: 5187
lastpage: 5197
page: 5187-5197
order: 5187
cycles: false
bibtex_author: Kerenidis, Iordanis and Luongo, Alessandro and Prakash, Anupam
author:
- given: Iordanis
  family: Kerenidis
- given: Alessandro
  family: Luongo
- given: Anupam
  family: Prakash
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/kerenidis20a/kerenidis20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
