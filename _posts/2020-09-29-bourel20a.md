---
title: Tightening Exploration in Upper Confidence Reinforcement Learning
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/bourel20a/bourel20a.pdf
url: http://proceedings.mlr.press/v119/bourel20a.html
abstract: 'The upper confidence reinforcement learning (UCRL2) algorithm introduced
  in \citep{jaksch2010near} is a popular method to perform regret minimization in
  unknown discrete Markov Decision Processes under the average-reward criterion. Despite
  its nice and generic theoretical regret guarantees, this algorithm and its variants
  have remained until now mostly theoretical as numerical experiments in simple environments
  exhibit long burn-in phases before the learning takes place. In pursuit of practical
  efficiency, we present UCRL3, following the lines of UCRL2, but with two key modifications:
  First, it uses state-of-the-art time-uniform concentration inequalities to compute
  confidence sets on the reward and (component-wise) transition distributions for
  each state-action pair. Furthermore, to tighten exploration, it uses an adaptive
  computation of the support of each transition distribution, which in turn enables
  us to revisit the extended value iteration procedure of UCRL2 to optimize over distributions
  with reduced support by disregarding low probability transitions, while still ensuring
  near-optimism. We demonstrate, through numerical experiments in standard environments,
  that reducing exploration this way yields a substantial numerical improvement compared
  to UCRL2 and its variants. On the theoretical side, these key modifications enable
  us to derive a regret bound for UCRL3 improving on UCRL2, that for the first time
  makes appear notions of local diameter and local effective support, thanks to variance-aware
  concentration bounds.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bourel20a
month: 0
tex_title: Tightening Exploration in Upper Confidence Reinforcement Learning
firstpage: 1056
lastpage: 1066
page: 1056-1066
order: 1056
cycles: false
bibtex_author: Bourel, Hippolyte and Maillard, Odalric and Talebi, Mohammad Sadegh
author:
- given: Hippolyte
  family: Bourel
- given: Odalric
  family: Maillard
- given: Mohammad Sadegh
  family: Talebi
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/bourel20a/bourel20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
