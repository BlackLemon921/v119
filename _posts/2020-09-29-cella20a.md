---
title: Meta-learning with Stochastic Linear Bandits
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/cella20a/cella20a.pdf
url: http://proceedings.mlr.press/v119/cella20a.html
abstract: We investigate meta-learning procedures in the setting of stochastic linear
  bandits tasks. The goal is to select a learning algorithm which works well on average
  over a class of bandits tasks, that are sampled from a task-distribution. Inspired
  by recent work on learning-to-learn linear regression, we consider a class of bandit
  algorithms that implement a regularized version of the well-known OFUL algorithm,
  where the regularization is a square euclidean distance to a bias vector. We first
  study the benefit of the biased OFUL algorithm in terms of regret minimization.
  We then propose two strategies to estimate the bias within the learning-to-learn
  setting. We show both theoretically and experimentally, that when the number of
  tasks grows and the variance of the task-distribution is small, our strategies have
  a significant advantage over learning the tasks in isolation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cella20a
month: 0
tex_title: Meta-learning with Stochastic Linear Bandits
firstpage: 1360
lastpage: 1370
page: 1360-1370
order: 1360
cycles: false
bibtex_author: Cella, Leonardo and Lazaric, Alessandro and Pontil, Massimiliano
author:
- given: Leonardo
  family: Cella
- given: Alessandro
  family: Lazaric
- given: Massimiliano
  family: Pontil
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/cella20a/cella20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
