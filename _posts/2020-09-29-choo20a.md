---
title: 'k-means++: few more steps yield constant approximation'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/choo20a/choo20a.pdf
url: http://proceedings.mlr.press/v119/choo20a.html
abstract: The k-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is a state-of-the-art
  algorithm for solving the k-means clustering problem and is known to give an O(log
  k) approximation. Recently, Lattanzi and Sohler (ICML 2019) proposed augmenting
  k-means++ with O(k log log k) local search steps to yield a constant approximation
  (in expectation) to the k-means clustering problem. In this paper, we improve their
  analysis to show that, for any arbitrarily small constant epsilon > 0, with only
  epsilon * k additional local search steps, one can achieve a constant approximation
  guarantee (with high probability in k), resolving an open problem in their paper.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: choo20a
month: 0
tex_title: 'k-means++: few more steps yield constant approximation'
firstpage: 1909
lastpage: 1917
page: 1909-1917
order: 1909
cycles: false
bibtex_author: Choo, Davin and Grunau, Christoph and Portmann, Julian and Rozhon,
  Vaclav
author:
- given: Davin
  family: Choo
- given: Christoph
  family: Grunau
- given: Julian
  family: Portmann
- given: Vaclav
  family: Rozhon
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/choo20a/choo20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
