---
title: Learning with Good Feature Representations in Bandits and in RL with a Generative
  Model
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/lattimore20a/lattimore20a.pdf
url: http://proceedings.mlr.press/v119/lattimore20a.html
abstract: The construction in the recent paper by Du et al. [2019] implies that searching
  for a near-optimal action in a bandit sometimes requires examining essentially all
  the actions, even if the learner is given linear features in R^d that approximate
  the rewards with a small uniform error. We use the Kiefer-Wolfowitz theorem to prove
  a positive result that by checking only a few actions, a learner can always find
  an action that is suboptimal with an error of at most O($\epsilon$$\sqrt{}$d) where
  $\epsilon$ is the approximation error of the features. Thus, features are useful
  when the approximation error is small relative to the dimensionality of the features.
  The idea is applied to stochastic bandits and reinforcement learning with a generative
  model where the learner has access to d-dimensional linear features that approximate
  the action-value functions for all policies to an accuracy of $\epsilon$. For linear
  bandits, we prove a bound on the regret of order d$\sqrt{}$(n log(k)) + $\epsilon$n$\sqrt{}$d
  log(n) with k the number of actions and n the horizon. For RL we show that approximate
  policy iteration can learn a policy that is optimal up to an additive error of order
  $\epsilon$$\sqrt{}$d/(1 − $\gamma$)^2 and using about d/($\epsilon$^2(1 − $\gamma$)^4)
  samples from the generative model. These bounds are independent of the finer details
  of the features. We also investigate how the structure of the feature set impacts
  the tradeoff between sample complexity and estimation error.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lattimore20a
month: 0
tex_title: Learning with Good Feature Representations in Bandits and in {RL} with
  a Generative Model
firstpage: 5662
lastpage: 5670
page: 5662-5670
order: 5662
cycles: false
bibtex_author: Lattimore, Tor and Szepesvari, Csaba and Weisz, Gellert
author:
- given: Tor
  family: Lattimore
- given: Csaba
  family: Szepesvari
- given: Gellert
  family: Weisz
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/lattimore20a/lattimore20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
