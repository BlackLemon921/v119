---
title: Anderson Acceleration of Proximal Gradient Methods
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/mai20a/mai20a.pdf
url: http://proceedings.mlr.press/v119/mai20a.html
abstract: Anderson acceleration is a well-established and simple technique for speeding
  up fixed-point computations with countless applications. This work introduces novel
  methods for adapting Anderson acceleration to proximal gradient algorithms. Under
  some technical conditions, we extend existing local convergence results of Anderson
  acceleration for smooth fixed-point mappings to the proposed non-smooth setting.
  We also prove analytically that it is in general, impossible to guarantee global
  convergence of native Anderson acceleration. We therefore propose a simple scheme
  for stabilization that combines the global worst-case guarantees of proximal gradient
  methods with the local adaptation and practical speed-up of Anderson acceleration.
  Finally, we provide the first applications of Anderson acceleration to non-Euclidean
  geometry.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mai20a
month: 0
tex_title: Anderson Acceleration of Proximal Gradient Methods
firstpage: 6620
lastpage: 6629
page: 6620-6629
order: 6620
cycles: false
bibtex_author: Mai, Vien and Johansson, Mikael
author:
- given: Vien
  family: Mai
- given: Mikael
  family: Johansson
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
software: https://github.com/vienmai/AA-Prox
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/mai20a/mai20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
