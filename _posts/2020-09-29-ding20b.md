---
title: Generalization Guarantees for Sparse Kernel Approximation with Entropic Optimal
  Features
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/ding20b/ding20b.pdf
url: http://proceedings.mlr.press/v119/ding20b.html
abstract: Despite their success, kernel methods suffer from a massive computational
  cost in practice. In this paper, in lieu of commonly used kernel expansion with
  respect to $N$ inputs, we develop a novel optimal design maximizing the entropy
  among kernel features. This procedure results in a kernel expansion with respect
  to entropic optimal features (EOF), improving the data representation dramatically
  due to features dissimilarity. Under mild technical assumptions, our generalization
  bound shows that with only $O(N^{\frac{1}{4}})$ features (disregarding logarithmic
  factors), we can achieve the optimal statistical accuracy (i.e., $O(1/\sqrt{N})$).
  The salient feature of our design is its sparsity that significantly reduces the
  time and space costs. Our numerical experiments on benchmark datasets verify the
  superiority of EOF over the state-of-the-art in kernel approximation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding20b
month: 0
tex_title: Generalization Guarantees for Sparse Kernel Approximation with Entropic
  Optimal Features
firstpage: 2545
lastpage: 2555
page: 2545-2555
order: 2545
cycles: false
bibtex_author: Ding, Liang and Tuo, Rui and Shahrampour, Shahin
author:
- given: Liang
  family: Ding
- given: Rui
  family: Tuo
- given: Shahin
  family: Shahrampour
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/ding20b/ding20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
