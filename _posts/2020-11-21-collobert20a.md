---
title: Word-Level Speech Recognition With a Letter to Word Encoder
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/collobert20a/collobert20a.pdf
url: http://proceedings.mlr.press/v119/collobert20a.html
abstract: We propose a direct-to-word sequence model which uses a word network to
  learn word embeddings from letters. The word network can be integrated seamlessly
  with arbitrary sequence models including Connectionist Temporal Classification and
  encoder-decoder models with attention. We show our direct-to-word model can achieve
  word error rate gains over sub-word level models for speech recognition. We also
  show that our direct-to-word approach retains the ability to predict words not seen
  at training time without any retraining. Finally, we demonstrate that a word-level
  model can use a larger stride than a sub-word level model while maintaining accuracy.
  This makes the model more efficient both for training and inference.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: collobert20a
month: 0
tex_title: Word-Level Speech Recognition With a Letter to Word Encoder
firstpage: 2100
lastpage: 2110
page: 2100-2110
order: 2100
cycles: false
bibtex_author: Collobert, Ronan and Hannun, Awni and Synnaeve, Gabriel
author:
- given: Ronan
  family: Collobert
- given: Awni
  family: Hannun
- given: Gabriel
  family: Synnaeve
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
