---
title: Information-Theoretic Local Minima Characterization and Regularization
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/jia20a/jia20a.pdf
url: http://proceedings.mlr.press/v119/jia20a.html
abstract: Recent advances in deep learning theory have evoked the study of generalizability
  across different local minima of deep neural networks (DNNs). While current work
  focused on either discovering properties of good local minima or developing regularization
  techniques to induce good local minima, no approach exists that can tackle both
  problems. We achieve these two goals successfully in a unified manner. Specifically,
  based on the observed Fisher information we propose a metric both strongly indicative
  of generalizability of local minima and effectively applied as a practical regularizer.
  We provide theoretical analysis including a generalization bound and empirically
  demonstrate the success of our approach in both capturing and improving the generalizability
  of DNNs. Experiments are performed on CIFAR-10, CIFAR-100 and ImageNet for various
  network architectures.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jia20a
month: 0
tex_title: Information-Theoretic Local Minima Characterization and Regularization
firstpage: 4773
lastpage: 4783
page: 4773-4783
order: 4773
cycles: false
bibtex_author: Jia, Zhiwei and Su, Hao
author:
- given: Zhiwei
  family: Jia
- given: Hao
  family: Su
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
software: https://github.com/SeanJia/InfoMCR
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/jia20a/jia20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
