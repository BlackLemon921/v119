---
title: A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/xu20c/xu20c.pdf
url: http://proceedings.mlr.press/v119/xu20c.html
abstract: Q-learning with neural network function approximation (neural Q-learning
  for short) is among the most prevalent deep reinforcement learning algorithms. Despite
  its empirical success, the non-asymptotic convergence rate of neural Q-learning
  remains virtually unknown. In this paper, we present a finite-time analysis of a
  neural Q-learning algorithm, where the data are generated from a Markov decision
  process, and the action-value function is approximated by a deep ReLU neural network.
  We prove that neural Q-learning finds the optimal policy with an $O(1/\sqrt{T})$
  convergence rate if the neural function approximator is sufficiently overparameterized,
  where $T$ is the number of iterations. To our best knowledge, our result is the
  first finite-time analysis of neural Q-learning under non-i.i.d. data assumption.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu20c
month: 0
tex_title: A Finite-Time Analysis of Q-Learning with Neural Network Function Approximation
firstpage: 10555
lastpage: 10565
page: 10555-10565
order: 10555
cycles: false
bibtex_author: Xu, Pan and Gu, Quanquan
author:
- given: Pan
  family: Xu
- given: Quanquan
  family: Gu
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/xu20c/xu20c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
