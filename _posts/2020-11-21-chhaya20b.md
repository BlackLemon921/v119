---
title: On Coresets for Regularized Regression
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/chhaya20b/chhaya20b.pdf
url: http://proceedings.mlr.press/v119/chhaya20b.html
abstract: We study the effect of norm based regularization on the size of coresets
  for regression problems. Specifically, given a matrix $ \mathbf{A} \in {\mathbb{R}}^{n
  \times d}$ with $n\gg d$ and a vector $\mathbf{b} \in \mathbb{R} ^ n $ and $\lambda
  > 0$, we analyze the size of coresets for regularized versions of regression of
  the form $\|\mathbf{Ax}-\mathbf{b}\|_p^r + \lambda\|{\mathbf{x}}\|_q^s$. Prior work
  has shown that for ridge regression (where $p,q,r,s=2$) we can obtain a coreset
  that is smaller than the coreset for the unregularized counterpart i.e. least squares
  regressionÂ \cite{avron2017sharper}. We show that when $r \neq s$, no coreset for
  regularized regression can have size smaller than the optimal coreset of the unregularized
  version. The well known lasso problem falls under this category and hence does not
  allow a coreset smaller than the one for least squares regression. We propose a
  modified version of the lasso problem and obtain for it a coreset of size smaller
  than the least square regression. We empirically show that the modified version
  of lasso also induces sparsity in solution, similar to the original lasso. We also
  obtain smaller coresets for $\ell_p$ regression with $\ell_p$ regularization. We
  extend our methods to multi response regularized regression. Finally, we empirically
  demonstrate the coreset performance for the modified lasso and the $\ell_1$ regression
  with $\ell_1$ regularization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chhaya20b
month: 0
tex_title: On Coresets for Regularized Regression
firstpage: 1866
lastpage: 1876
page: 1866-1876
order: 1866
cycles: false
bibtex_author: Chhaya, Rachit and Dasgupta, Anirban and Shit, Supratim
author:
- given: Rachit
  family: Chhaya
- given: Anirban
  family: Dasgupta
- given: Supratim
  family: Shit
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/chhaya20b/chhaya20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
