---
title: Understanding Self-Training for Gradual Domain Adaptation
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/kumar20c/kumar20c.pdf
url: http://proceedings.mlr.press/v119/kumar20c.html
abstract: Machine learning systems must adapt to data distributions that evolve over
  time, in applications ranging from sensor networks and self-driving car perception
  modules to brain-machine interfaces. Traditional domain adaptation is only guaranteed
  to work when the distribution shift is small; empirical methods combine several
  heuristics for larger shifts but can be dataset specific. To adapt to larger shifts
  we consider gradual domain adaptation, where the goal is to adapt an initial classifier
  trained on a source domain given only unlabeled data that shifts gradually in distribution
  towards a target domain. We prove the first non-vacuous upper bound on the error
  of self-training with gradual shifts, under settings where directly adapting to
  the target domain can result in unbounded error. The theoretical analysis leads
  to algorithmic insights, highlighting that regularization and label sharpening are
  essential even when we have infinite data. Leveraging the gradual shift structure
  leads to higher accuracies on a rotating MNIST dataset, a forest Cover Type dataset,
  and a realistic Portraits dataset.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kumar20c
month: 0
tex_title: Understanding Self-Training for Gradual Domain Adaptation
firstpage: 5468
lastpage: 5479
page: 5468-5479
order: 5468
cycles: false
bibtex_author: Kumar, Ananya and Ma, Tengyu and Liang, Percy
author:
- given: Ananya
  family: Kumar
- given: Tengyu
  family: Ma
- given: Percy
  family: Liang
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
software: https://github.com/p-lambda/gradual_domain_adaptation
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/kumar20c/kumar20c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
