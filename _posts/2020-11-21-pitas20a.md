---
title: Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/pitas20a/pitas20a.pdf
url: http://proceedings.mlr.press/v119/pitas20a.html
abstract: Explaining how overparametrized neural networks simultaneously achieve low
  risk and zero empirical risk on benchmark datasets is an open problem. PAC-Bayes
  bounds optimized using variational inference (VI) have been recently proposed as
  a promising direction in obtaining non-vacuous bounds. We show empirically that
  this approach gives negligible gains when modelling the posterior as a Gaussian
  with diagonal covarianceâ€”known as the mean-field approximation. We investigate common
  explanations, such as the failure of VI due to problems in optimization or choosing
  a suboptimal prior. Our results suggest that investigating richer posteriors is
  the most promising direction forward.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pitas20a
month: 0
tex_title: Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation
firstpage: 7739
lastpage: 7749
page: 7739-7749
order: 7739
cycles: false
bibtex_author: Pitas, Konstantinos
author:
- given: Konstantinos
  family: Pitas
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/pitas20a/pitas20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
