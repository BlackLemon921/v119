---
title: 'Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization
  Formulations for Two-layer Networks'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/pilanci20a/pilanci20a.pdf
url: http://proceedings.mlr.press/v119/pilanci20a.html
abstract: We develop exact representations of training two-layer neural networks with
  rectified linear units (ReLUs) in terms of a single convex program with number of
  variables polynomial in the number of training samples and the number of hidden
  neurons. Our theory utilizes semi-infinite duality and minimum norm regularization.
  We show that ReLU networks trained with standard weight decay are equivalent to
  block $\ell_1$ penalized convex models. Moreover, we show that certain standard
  convolutional linear networks are equivalent semi-definite programs which can be
  simplified to $\ell_1$ regularized linear models in a polynomial sized discrete
  Fourier feature space
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pilanci20a
month: 0
tex_title: 'Neural Networks are Convex Regularizers: Exact Polynomial-time Convex
  Optimization Formulations for Two-layer Networks'
firstpage: 7695
lastpage: 7705
page: 7695-7705
order: 7695
cycles: false
bibtex_author: Pilanci, Mert and Ergen, Tolga
author:
- given: Mert
  family: Pilanci
- given: Tolga
  family: Ergen
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/pilanci20a/pilanci20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
