---
title: Stabilizing Transformers for Reinforcement Learning
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/parisotto20a/parisotto20a.pdf
url: http://proceedings.mlr.press/v119/parisotto20a.html
abstract: Owing to their ability to both effectively integrate information over long
  time horizons and scale to massive amounts of data, self-attention architectures
  have recently shown breakthrough success in natural language processing (NLP). Harnessing
  the transformer’s ability to process long time horizons of information could provide
  a similar performance boost in partially observable reinforcement learning (RL)
  domains, but the large-scale transformers used in NLP have yet to be successfully
  applied to the RL setting. In this work we demonstrate that the standard transformer
  architecture is difficult to optimize, which was previously observed in the supervised
  learning setting but becomes especially pronounced with RL objectives. We propose
  architectural modifications that substantially improve the stability and learning
  speed of the original Transformer and XL variant. The proposed architecture, the
  Gated Transformer-XL (GTrXL), surpasses LSTMs on challenging memory environments
  and achieves state-of-the-art results on the multi-task DMLab-30 benchmark suite,
  exceeding the performance of an external memory architecture. We show that the GTrXL
  has stability and performance that consistently matches or exceeds a competitive
  LSTM baseline, including on more reactive tasks where memory is less critical.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: parisotto20a
month: 0
tex_title: Stabilizing Transformers for Reinforcement Learning
firstpage: 7487
lastpage: 7498
page: 7487-7498
order: 7487
cycles: false
bibtex_author: Parisotto, Emilio and Song, Francis and Rae, Jack and Pascanu, Razvan
  and Gulcehre, Caglar and Jayakumar, Siddhant and Jaderberg, Max and Kaufman, Rapha{\"e}l
  Lopez and Clark, Aidan and Noury, Seb and Botvinick, Matthew and Heess, Nicolas
  and Hadsell, Raia
author:
- given: Emilio
  family: Parisotto
- given: Francis
  family: Song
- given: Jack
  family: Rae
- given: Razvan
  family: Pascanu
- given: Caglar
  family: Gulcehre
- given: Siddhant
  family: Jayakumar
- given: Max
  family: Jaderberg
- given: Raphaël Lopez
  family: Kaufman
- given: Aidan
  family: Clark
- given: Seb
  family: Noury
- given: Matthew
  family: Botvinick
- given: Nicolas
  family: Heess
- given: Raia
  family: Hadsell
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/parisotto20a/parisotto20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
