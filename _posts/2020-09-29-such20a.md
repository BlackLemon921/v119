---
title: 'Generative Teaching Networks: Accelerating Neural Architecture Search by Learning
  to Generate Synthetic Training Data'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/such20a/such20a.pdf
url: http://proceedings.mlr.press/v119/such20a.html
abstract: 'This paper investigates the intriguing question of whether we can create
  learning algorithms that automatically generate training data, learning environments,
  and curricula in order to help AI agents rapidly learn. We show that such algorithms
  are possible via Generative Teaching Networks (GTNs), a general approach that is,
  in theory, applicable to supervised, unsupervised, and reinforcement learning, although
  our experiments only focus on the supervised case. GTNs are deep neural networks
  that generate data and/or training environments that a learner (e.g. a freshly initialized
  neural network) trains on for a few SGD steps before being tested on a target task.
  We then differentiate \emph{through the entire learning process} via meta-gradients
  to update the GTN parameters to improve performance on the target task. This paper
  introduces GTNs, discusses their potential, and showcases that they can substantially
  accelerate learning. We also demonstrate a practical and exciting application of
  GTNs: accelerating the evaluation of candidate architectures for neural architecture
  search (NAS). GTN-NAS improves the NAS state of the art, finding higher performing
  architectures when controlling for the search proposal mechanism. GTN-NAS also is
  competitive with the overall state of the art approaches, which achieve top performance
  while using orders of magnitude less computation than typical NAS methods. Speculating
  forward, GTNs may represent a first step toward the ambitious goal of algorithms
  that generate their own training data and, in doing so, open a variety of interesting
  new research questions and directions.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: such20a
month: 0
tex_title: 'Generative Teaching Networks: Accelerating Neural Architecture Search
  by Learning to Generate Synthetic Training Data'
firstpage: 9206
lastpage: 9216
page: 9206-9216
order: 9206
cycles: false
bibtex_author: Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley,
  Kenneth and Clune, Jeffrey
author:
- given: Felipe Petroski
  family: Such
- given: Aditya
  family: Rawal
- given: Joel
  family: Lehman
- given: Kenneth
  family: Stanley
- given: Jeffrey
  family: Clune
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
software: https://github.com/uber-research/GTN
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/such20a/such20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
