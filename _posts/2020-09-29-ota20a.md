---
title: Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/ota20a/ota20a.pdf
url: http://proceedings.mlr.press/v119/ota20a.html
abstract: Deep reinforcement learning (RL) algorithms have recently achieved remarkable
  successes in various sequential decision making tasks, leveraging advances in methods
  for training large deep networks. However, these methods usually require large amounts
  of training data, which is often a big problem for real-world applications. One
  natural question to ask is whether learning good representations for states and
  using larger networks helps in learning better policies. In this paper, we try to
  study if increasing input dimensionality helps improve performance and sample efficiency
  of model-free deep RL algorithms. To do so, we propose an online feature extractor
  network (OFENet) that uses neural nets to produce \emph{good} representations to
  be used as inputs to an off-policy RL algorithm. Even though the high dimensionality
  of input is usually thought to make learning of RL agents more difficult, we show
  that the RL agents in fact learn more efficiently with the high-dimensional representation
  than with the lower-dimensional state observations. We believe that stronger feature
  propagation together with larger networks allows RL agents to learn more complex
  functions of states and thus improves the sample efficiency. Through numerical experiments,
  we show that the proposed method achieves much higher sample efficiency and better
  performance. Codes for the proposed method are available at http://www.merl.com/research/license/OFENet
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ota20a
month: 0
tex_title: Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?
firstpage: 7424
lastpage: 7433
page: 7424-7433
order: 7424
cycles: false
bibtex_author: Ota, Kei and Oiki, Tomoaki and Jha, Devesh and Mariyama, Toshisada
  and Nikovski, Daniel
author:
- given: Kei
  family: Ota
- given: Tomoaki
  family: Oiki
- given: Devesh
  family: Jha
- given: Toshisada
  family: Mariyama
- given: Daniel
  family: Nikovski
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/ota20a/ota20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
