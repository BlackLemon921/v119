---
title: Leveraging Procedural Generation to Benchmark Reinforcement Learning
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/cobbe20a/cobbe20a.pdf
url: http://proceedings.mlr.press/v119/cobbe20a.html
abstract: We introduce Procgen Benchmark, a suite of 16 procedurally generated game-like
  environments designed to benchmark both sample efficiency and generalization in
  reinforcement learning. We believe that the community will benefit from increased
  access to high quality training environments, and we provide detailed experimental
  protocols for using this benchmark. We empirically demonstrate that diverse environment
  distributions are essential to adequately train and evaluate RL agents, thereby
  motivating the extensive use of procedural content generation. We then use this
  benchmark to investigate the effects of scaling model size, finding that larger
  models significantly improve both sample efficiency and generalization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cobbe20a
month: 0
tex_title: Leveraging Procedural Generation to Benchmark Reinforcement Learning
firstpage: 2048
lastpage: 2056
page: 2048-2056
order: 2048
cycles: false
bibtex_author: Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John
author:
- given: Karl
  family: Cobbe
- given: Chris
  family: Hesse
- given: Jacob
  family: Hilton
- given: John
  family: Schulman
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/cobbe20a/cobbe20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
