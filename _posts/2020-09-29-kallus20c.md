---
title: Statistically Efficient Off-Policy Policy Gradients
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/kallus20c/kallus20c.pdf
url: http://proceedings.mlr.press/v119/kallus20c.html
abstract: Policy gradient methods in reinforcement learning update policy parameters
  by taking steps in the direction of an estimated gradient of policy value. In this
  paper, we consider the efficient estimation of policy gradients from off-policy
  data, where the estimation is particularly non-trivial. We derive the asymptotic
  lower bound on the feasible mean-squared error in both Markov and non-Markov decision
  processes and show that existing estimators fail to achieve it in general settings.
  We propose a meta-algorithm that achieves the lower bound without any parametric
  assumptions and exhibits a unique 4-way double robustness property. We discuss how
  to estimate nuisances that the algorithm relies on. Finally, we establish guarantees
  at the rate at which we approach a stationary point when we take steps in the direction
  of our new estimated policy gradient.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kallus20c
month: 0
tex_title: Statistically Efficient Off-Policy Policy Gradients
firstpage: 5089
lastpage: 5100
page: 5089-5100
order: 5089
cycles: false
bibtex_author: Kallus, Nathan and Uehara, Masatoshi
author:
- given: Nathan
  family: Kallus
- given: Masatoshi
  family: Uehara
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/kallus20c/kallus20c-supp.pdf
- label: Other Files
  link: https://media.icml.cc/Conferences/ICML2020/v119/kallus20c-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
