---
title: Closing the convergence gap of SGD without replacement
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/rajput20a/rajput20a.pdf
url: http://proceedings.mlr.press/v119/rajput20a.html
abstract: Stochastic gradient descent without replacement sampling is widely used
  in practice for model training. However, the vast majority of SGD analyses assumes
  data is sampled with replacement, and when the function minimized is strongly convex,
  an $\mathcal{O}\left(\frac{1}{T}\right)$ rate can be established when SGD is run
  for $T$ iterations. A recent line of breakthrough works on SGD without replacement
  (SGDo) established an $\mathcal{O}\left(\frac{n}{T^2}\right)$ convergence rate when
  the function minimized is strongly convex and is a sum of $n$ smooth functions,
  and an $\mathcal{O}\left(\frac{1}{T^2}+\frac{n^3}{T^3}\right)$ rate for sums of
  quadratics. On the other hand, the tightest known lower bound postulates an $\Omega\left(\frac{1}{T^2}+\frac{n^2}{T^3}\right)$
  rate, leaving open the possibility of better SGDo convergence rates in the general
  case. In this paper, we close this gap and show that SGD without replacement achieves
  a rate of $\mathcal{O}\left(\frac{1}{T^2}+\frac{n^2}{T^3}\right)$ when the sum of
  the functions is a quadratic, and offer a new lower bound of $\Omega\left(\frac{n}{T^2}\right)$
  for strongly convex functions that are sums of smooth functions.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rajput20a
month: 0
tex_title: Closing the convergence gap of {SGD} without replacement
firstpage: 7964
lastpage: 7973
page: 7964-7973
order: 7964
cycles: false
bibtex_author: Rajput, Shashank and Gupta, Anant and Papailiopoulos, Dimitris
author:
- given: Shashank
  family: Rajput
- given: Anant
  family: Gupta
- given: Dimitris
  family: Papailiopoulos
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
software: https://github.com/shashankrajput/SGDo
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/rajput20a/rajput20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
