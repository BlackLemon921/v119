---
title: Abstraction Mechanisms Predict Generalization in Deep Neural Networks
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/gain20a/gain20a.pdf
url: http://proceedings.mlr.press/v119/gain20a.html
abstract: A longstanding problem for Deep Neural Networks (DNNs) is understanding
  their puzzling ability to generalize well. We approach this problem through the
  unconventional angle of \emph{cognitive abstraction mechanisms}, drawing inspiration
  from recent neuroscience work, allowing us to define the Cognitive Neural Activation
  metric (CNA) for DNNs, which is the correlation between information complexity (entropy)
  of given input and the concentration of higher activation values in deeper layers
  of the network. The CNA is highly predictive of generalization ability, outperforming
  norm-and-sharpness-based generalization metrics on an extensive evaluation of close
  to 200 network instances comprising a breadth of dataset-architecture combinations,
  especially in cases where additive noise is present and/or training labels are corrupted.
  These strong empirical results show the usefulness of the CNA as a generalization
  metric and encourage further research on the connection between information complexity
  and representations in the deeper layers of networks in order to better understand
  the generalization capabilities of DNNs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gain20a
month: 0
tex_title: Abstraction Mechanisms Predict Generalization in Deep Neural Networks
firstpage: 3357
lastpage: 3366
page: 3357-3366
order: 3357
cycles: false
bibtex_author: Gain, Alex and Siegelmann, Hava
author:
- given: Alex
  family: Gain
- given: Hava
  family: Siegelmann
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
software: https://github.com/alexgain/cna-icml2020
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/gain20a/gain20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
