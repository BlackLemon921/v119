---
title: 'UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training'
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/bao20a/bao20a.pdf
url: http://proceedings.mlr.press/v119/bao20a.html
abstract: We propose to pre-train a unified language model for both autoencoding and
  partially autoregressive language modeling tasks using a novel training procedure,
  referred to as a pseudo-masked language model (PMLM). Given an input text with masked
  tokens, we rely on conventional masks to learn inter-relations between corrupted
  tokens and context via autoencoding, and pseudo masks to learn intra-relations between
  masked spans via partially autoregressive modeling. With well-designed position
  embeddings and self-attention masks, the context encodings are reused to avoid redundant
  computation. Moreover, conventional masks used for autoencoding provide global masking
  information, so that all the position embeddings are accessible in partially autoregressive
  language modeling. In addition, the two tasks pre-train a unified language model
  as a bidirectional encoder and a sequence-to-sequence decoder, respectively. Our
  experiments show that the unified language models pre-trained using PMLM achieve
  new state-of-the-art results on a wide range of language understanding and generation
  tasks across several widely used benchmarks. The code and pre-trained models are
  available at https://github.com/microsoft/unilm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bao20a
month: 0
tex_title: "{U}ni{LM}v2: Pseudo-Masked Language Models for Unified Language Model
  Pre-Training"
firstpage: 642
lastpage: 652
page: 642-652
order: 642
cycles: false
bibtex_author: Bao, Hangbo and Dong, Li and Wei, Furu and Wang, Wenhui and Yang, Nan
  and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Piao, Songhao and Zhou, Ming
  and Hon, Hsiao-Wuen
author:
- given: Hangbo
  family: Bao
- given: Li
  family: Dong
- given: Furu
  family: Wei
- given: Wenhui
  family: Wang
- given: Nan
  family: Yang
- given: Xiaodong
  family: Liu
- given: Yu
  family: Wang
- given: Jianfeng
  family: Gao
- given: Songhao
  family: Piao
- given: Ming
  family: Zhou
- given: Hsiao-Wuen
  family: Hon
date: 2020-11-21
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 11
  - 21
software: https://github.com/microsoft/unilm
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/bao20a/bao20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
