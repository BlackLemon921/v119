---
title: Thompson Sampling Algorithms for Mean-Variance Bandits
booktitle: Proceedings of the 37th International Conference on Machine Learning
year: '2020'
pdf: http://proceedings.mlr.press/v119/zhu20d/zhu20d.pdf
url: http://proceedings.mlr.press/v119/zhu20d.html
abstract: The multi-armed bandit (MAB) problem is a classical learning task that exemplifies
  the exploration-exploitation tradeoff. However, standard formulations do not take
  into account risk. In online decision making systems, risk is a primary concern.
  In this regard, the mean-variance risk measure is one of the most common objective
  functions. Existing algorithms for mean-variance optimization in the context of
  MAB problems have unrealistic assumptions on the reward distributions. We develop
  Thompson Sampling-style algorithms for mean-variance MAB and provide comprehensive
  regret analyses for Gaussian and Bernoulli bandits with fewer assumptions. Our algorithms
  achieve the best known regret bounds for mean-variance MABs and also attain the
  information-theoretic bounds in some parameter regimes. Empirical simulations show
  that our algorithms significantly outperform existing LCB-based algorithms for all
  risk tolerances.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu20d
month: 0
tex_title: Thompson Sampling Algorithms for Mean-Variance Bandits
firstpage: 11599
lastpage: 11608
page: 11599-11608
order: 11599
cycles: false
bibtex_author: Zhu, Qiuyu and Tan, Vincent
author:
- given: Qiuyu
  family: Zhu
- given: Vincent
  family: Tan
date: 2020-09-29
address: 
container-title: Proceedings of the 37th International Conference on Machine Learning
volume: '119'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 29
software: https://github.com/maxqyzhu/TS_for_mean_variance_bandit
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v119/zhu20d/zhu20d-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
